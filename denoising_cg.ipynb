{"cells":[{"cell_type":"markdown","metadata":{"id":"_xnMOsbqHz61"},"source":["# CycleGAN for Document Denoising"]},{"cell_type":"markdown","metadata":{"id":"ITZuApL56Mny"},"source":["## About CycleGAN\n","\n","CycleGAN uses a cycle consistency loss to enable training without the need for paired data. In other words, it can translate from one domain to another without a one-to-one mapping between the source and target domain. \n","\n","This opens up the possibility to do a lot of interesting tasks like photo-enhancement, image colorization, style transfer, etc. All you need is the source and the target dataset (which is simply a directory of images).\n","\n","![CycleGAN Image 1](https://miro.medium.com/max/1400/1*-7JKDTvulO6o4t4RRU5MJQ.png)\n","Fig.1 Conversion of original dirty input to its translated clean output\n","![CycleGAN Image 2](https://miro.medium.com/max/1400/1*0C34D2bEHmiyTbNzH8o5nQ.png)\n","Fig.2 Conversion of original clean input to its translated dirty output"]},{"cell_type":"markdown","metadata":{"id":"e1_Y75QXJS6h"},"source":["## Set up the input pipeline"]},{"cell_type":"markdown","metadata":{"id":"5fGHWOKPX4ta"},"source":["Install the [tensorflow_examples](https://github.com/tensorflow/examples) package that enables importing of the generator and the discriminator."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12025,"status":"ok","timestamp":1656149639500,"user":{"displayName":"Tianxiang Song","userId":"08920423447324048972"},"user_tz":-60},"id":"bJ1ROiQxJ-vY","outputId":"87ea3f90-e5c4-47f2-df0a-610c2c757e80","vscode":{"languageId":"python"}},"outputs":[],"source":["!pip install git+https://github.com/tensorflow/examples.git"]},{"cell_type":"markdown","metadata":{"id":"W6h-EBccgb67"},"source":["## Import libraries and data"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3798,"status":"ok","timestamp":1656149643261,"user":{"displayName":"Tianxiang Song","userId":"08920423447324048972"},"user_tz":-60},"id":"YfIk2es3hJEd","vscode":{"languageId":"python"}},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow_examples.models.pix2pix import pix2pix\n","\n","import os\n","import cv2\n","import numpy as np\n","from PIL import Image\n","\n","AUTOTUNE = tf.data.AUTOTUNE"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15913,"status":"ok","timestamp":1656149662223,"user":{"displayName":"Tianxiang Song","userId":"08920423447324048972"},"user_tz":-60},"id":"iuGVPOo7Cce0","outputId":"3f8bdb54-193d-4977-b2c4-1e2f8eed0aa3","vscode":{"languageId":"python"}},"outputs":[],"source":["# special need for Google Colab\n","from google.colab import drive\n","drive.mount('/content/drive')\n","os.chdir(\"/content/drive/MyDrive/ColabNotebooks/DocDenoise\")\n","!ls"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":280,"status":"ok","timestamp":1656149662493,"user":{"displayName":"Tianxiang Song","userId":"08920423447324048972"},"user_tz":-60},"id":"kcwwQsfEqlfH","outputId":"4b449baf-29ec-449c-a61f-5180fba008af","vscode":{"languageId":"python"}},"outputs":[],"source":["# check GPU details\n","!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":238,"status":"ok","timestamp":1656149718478,"user":{"displayName":"Tianxiang Song","userId":"08920423447324048972"},"user_tz":-60},"id":"EQ7WV_T2wfqC","vscode":{"languageId":"python"}},"outputs":[],"source":["# the whole data path\n","path = 'data/'\n","# the directory storing images to be processed\n","to_process_path = 'to_process/'\n","# the directory storing processed images\n","processed_path = 'processed/'\n","# list storing image filenames\n","to_process_img = sorted(os.listdir(path + to_process_path))"]},{"cell_type":"markdown","metadata":{"id":"bzp46qdDhbYB"},"source":["## Data preparation\n","Next step is to define function to process images and then store this images in list. As there is not as many data, we do not need to work in batches."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1656149720905,"user":{"displayName":"Tianxiang Song","userId":"08920423447324048972"},"user_tz":-60},"id":"Ss9qxw4twr4W","vscode":{"languageId":"python"}},"outputs":[],"source":["IMG_WIDTH = 3072\n","IMG_HEIGHT = 4096\n","\n","# prepare function\n","def process_image(path):\n","    img = cv2.imread(path)\n","    img = np.asarray(img, dtype=\"float32\")\n","    img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))\n","    img = img/255.0\n","    img = np.reshape(img, (IMG_HEIGHT, IMG_WIDTH, 3))\n","    \n","    return img"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":33630,"status":"ok","timestamp":1656149758576,"user":{"displayName":"Tianxiang Song","userId":"08920423447324048972"},"user_tz":-60},"id":"WaKiQuZmww5Y","outputId":"0b8a13a3-0249-4257-9287-c2b81a944bf3","vscode":{"languageId":"python"}},"outputs":[],"source":["# preprocess images\n","chinese_invoice = []\n","\n","for f in to_process_img:\n","    chinese_invoice.append(process_image(path + to_process_path + f))\n","\n","chinese_invoice = np.asarray(chinese_invoice)"]},{"cell_type":"markdown","metadata":{"id":"hvX8sKsfMaio"},"source":["## Import and reuse the Pix2Pix models"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5337,"status":"ok","timestamp":1656149766356,"user":{"displayName":"Tianxiang Song","userId":"08920423447324048972"},"user_tz":-60},"id":"8ju9Wyw87MRW","vscode":{"languageId":"python"}},"outputs":[],"source":["OUTPUT_CHANNELS = 3\n","\n","generator_g = pix2pix.unet_generator(OUTPUT_CHANNELS, norm_type='instancenorm')\n","generator_f = pix2pix.unet_generator(OUTPUT_CHANNELS, norm_type='instancenorm')\n","\n","discriminator_x = pix2pix.discriminator(norm_type='instancenorm', target=False)\n","discriminator_y = pix2pix.discriminator(norm_type='instancenorm', target=False)"]},{"cell_type":"markdown","metadata":{"id":"G-vjRM7IffTT"},"source":["Initialize the optimizers for all the generators and the discriminators."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1656149766357,"user":{"displayName":"Tianxiang Song","userId":"08920423447324048972"},"user_tz":-60},"id":"iWCn_PVdEJZ7","vscode":{"languageId":"python"}},"outputs":[],"source":["generator_g_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n","generator_f_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n","\n","discriminator_x_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n","discriminator_y_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)"]},{"cell_type":"markdown","metadata":{"id":"aKUZnDiqQrAh"},"source":["## Checkpoints"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15383,"status":"ok","timestamp":1656149782878,"user":{"displayName":"Tianxiang Song","userId":"08920423447324048972"},"user_tz":-60},"id":"WJnftd5sQsv6","outputId":"769115e2-d5e6-4b28-9ce6-3bd0be7522dd","vscode":{"languageId":"python"}},"outputs":[],"source":["checkpoint_path = \"./checkpoints/cycleGAN\"\n","\n","ckpt = tf.train.Checkpoint(generator_g=generator_g,\n","                           generator_f=generator_f,\n","                           discriminator_x=discriminator_x,\n","                           discriminator_y=discriminator_y,\n","                           generator_g_optimizer=generator_g_optimizer,\n","                           generator_f_optimizer=generator_f_optimizer,\n","                           discriminator_x_optimizer=discriminator_x_optimizer,\n","                           discriminator_y_optimizer=discriminator_y_optimizer)\n","\n","ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=1)\n","\n","# if a checkpoint exists, restore the latest checkpoint.\n","if ckpt_manager.latest_checkpoint:\n","  ckpt.restore(ckpt_manager.latest_checkpoint)\n","  print ('Latest checkpoint restored!!')"]},{"cell_type":"markdown","metadata":{"id":"1RGysMU_BZhx"},"source":["## Denoising and Save images"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":235,"status":"ok","timestamp":1656149785484,"user":{"displayName":"Tianxiang Song","userId":"08920423447324048972"},"user_tz":-60},"id":"CTDYhlLueXr3","vscode":{"languageId":"python"}},"outputs":[],"source":["def tensor_to_image(tensor):\n","    tensor = tensor*255\n","    tensor = np.array(tensor, dtype=np.uint8)\n","    if np.ndim(tensor)>3:\n","        assert tensor.shape[0] == 1\n","        tensor = tensor[0]\n","    return Image.fromarray(tensor)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IIkNJUuMZA5o","outputId":"4769fbc1-7ce3-42df-a36d-fab87f2a18e8","vscode":{"languageId":"python"}},"outputs":[],"source":["i = 0\n","for image in chinese_invoice:\n","  prediction = generator_g(image.reshape(1,IMG_HEIGHT,IMG_WIDTH,3))\n","  im_path = path + processed_path + to_process_img[i]\n","  im = tensor_to_image(prediction)\n","  im.save(im_path)\n","  i += 1"]},{"cell_type":"markdown","metadata":{"id":"ABGiHY6fE02b"},"source":["## Next steps\n","- Training the model on a larger dataset\n","- Tuning parameters to achieve greater performance\n","- Fine-tuning the models on a different dataset to implement more functions (e.g., watermark removal and motion deblur)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"chineseInvoice_cg.ipynb","provenance":[{"file_id":"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/cyclegan.ipynb","timestamp":1655569791492}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}
