{"cells":[{"cell_type":"code","execution_count":46,"metadata":{"executionInfo":{"elapsed":254,"status":"ok","timestamp":1657313854732,"user":{"displayName":"Michael S","userId":"03226043462629562395"},"user_tz":-60},"id":"NpEkxcbFzfzI"},"outputs":[],"source":["import os\n","import cv2\n","import imutils\n","import xlsxwriter\n","import numpy as np\n","from math import sqrt\n","from scipy.stats import mode\n","from skimage.feature import canny\n","from itertools import combinations\n","from sklearn.cluster import DBSCAN\n","from difflib import SequenceMatcher\n","from PIL import Image, ImageDraw, ImageFont\n","from skimage.transform import hough_line, hough_line_peaks\n","from paddleocr import PaddleOCR, PPStructure, save_structure_res"]},{"cell_type":"markdown","metadata":{},"source":["### Initialize PaddleOCR"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":54378,"status":"ok","timestamp":1657314084162,"user":{"displayName":"Michael S","userId":"03226043462629562395"},"user_tz":-60},"id":"7EEfG-kGzDdm","outputId":"989e63b3-431e-413f-fe64-34343019d606"},"outputs":[{"name":"stdout","output_type":"stream","text":["[2022/07/24 19:01:23] ppocr DEBUG: Namespace(alpha=1.0, benchmark=False, beta=1.0, cls_batch_num=6, cls_image_shape='3, 48, 192', cls_model_dir='/root/.paddleocr/whl/cls/ch_ppocr_mobile_v2.0_cls_infer', cls_thresh=0.9, cpu_threads=10, crop_res_save_dir='./output', det=True, det_algorithm='DB', det_db_box_thresh=0.6, det_db_score_mode='fast', det_db_thresh=0.3, det_db_unclip_ratio=1.5, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_east_score_thresh=0.8, det_fce_box_type='poly', det_limit_side_len=960, det_limit_type='max', det_model_dir='/root/.paddleocr/whl/det/ch/ch_PP-OCRv3_det_infer', det_pse_box_thresh=0.85, det_pse_box_type='quad', det_pse_min_area=16, det_pse_scale=1, det_pse_thresh=0, det_sast_nms_thresh=0.2, det_sast_polygon=False, det_sast_score_thresh=0.5, draw_img_save_dir='./inference_results', drop_score=0.5, e2e_algorithm='PGNet', e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_limit_side_len=768, e2e_limit_type='max', e2e_model_dir=None, e2e_pgnet_mode='fast', e2e_pgnet_score_thresh=0.5, e2e_pgnet_valid_set='totaltext', enable_mkldnn=False, fourier_degree=5, gpu_mem=500, help='==SUPPRESS==', image_dir=None, ir_optim=True, label_list=['0', '180'], lang='ch', layout=True, layout_label_map=None, layout_path_model='lp://PubLayNet/ppyolov2_r50vd_dcn_365e_publaynet/config', max_batch_size=10, max_text_length=25, min_subgraph_size=15, mode='structure', ocr=True, ocr_version='PP-OCRv3', output='./output', precision='fp32', process_id=0, rec=True, rec_algorithm='SVTR_LCNet', rec_batch_num=6, rec_char_dict_path='/usr/local/lib/python3.8/dist-packages/paddleocr/ppocr/utils/ppocr_keys_v1.txt', rec_image_shape='3, 48, 320', rec_model_dir='/root/.paddleocr/whl/rec/ch/ch_PP-OCRv3_rec_infer', save_crop_res=False, save_log_path='./log_output/', scales=[8, 16, 32], show_log=True, structure_version='PP-STRUCTURE', table=True, table_char_dict_path=None, table_max_len=488, table_model_dir=None, total_process_num=1, type='ocr', use_angle_cls=True, use_dilation=False, use_gpu=False, use_mp=False, use_onnx=False, use_pdserving=False, use_space_char=True, use_tensorrt=False, vis_font_path='./doc/fonts/simfang.ttf', warmup=False)\n","[2022/07/24 19:01:24] ppocr DEBUG: Namespace(alpha=1.0, benchmark=False, beta=1.0, cls_batch_num=6, cls_image_shape='3, 48, 192', cls_model_dir=None, cls_thresh=0.9, cpu_threads=10, crop_res_save_dir='./output', det=True, det_algorithm='DB', det_db_box_thresh=0.6, det_db_score_mode='fast', det_db_thresh=0.3, det_db_unclip_ratio=1.5, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_east_score_thresh=0.8, det_fce_box_type='poly', det_limit_side_len=960, det_limit_type='max', det_model_dir='/root/.paddleocr/whl/det/ch/ch_PP-OCRv3_det_infer', det_pse_box_thresh=0.85, det_pse_box_type='quad', det_pse_min_area=16, det_pse_scale=1, det_pse_thresh=0, det_sast_nms_thresh=0.2, det_sast_polygon=False, det_sast_score_thresh=0.5, draw_img_save_dir='./inference_results', drop_score=0.5, e2e_algorithm='PGNet', e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_limit_side_len=768, e2e_limit_type='max', e2e_model_dir=None, e2e_pgnet_mode='fast', e2e_pgnet_score_thresh=0.5, e2e_pgnet_valid_set='totaltext', enable_mkldnn=False, fourier_degree=5, gpu_mem=500, help='==SUPPRESS==', image_dir=None, ir_optim=True, label_list=['0', '180'], lang='ch', layout=True, layout_label_map=None, layout_path_model='lp://PubLayNet/ppyolov2_r50vd_dcn_365e_publaynet/config', max_batch_size=10, max_text_length=25, min_subgraph_size=15, mode='structure', ocr=True, ocr_version='PP-OCRv3', output='./output', precision='fp32', process_id=0, rec=True, rec_algorithm='SVTR_LCNet', rec_batch_num=6, rec_char_dict_path='/usr/local/lib/python3.8/dist-packages/paddleocr/ppocr/utils/ppocr_keys_v1.txt', rec_image_shape='3, 48, 320', rec_model_dir='/root/.paddleocr/whl/rec/ch/ch_PP-OCRv3_rec_infer', save_crop_res=False, save_log_path='./log_output/', scales=[8, 16, 32], show_log=True, structure_version='PP-STRUCTURE', table=True, table_char_dict_path='/usr/local/lib/python3.8/dist-packages/paddleocr/ppocr/utils/dict/table_structure_dict.txt', table_max_len=488, table_model_dir='/root/.paddleocr/whl/table/en_ppocr_mobile_v2.0_table_structure_infer', total_process_num=1, type='ocr', use_angle_cls=False, use_dilation=False, use_gpu=False, use_mp=False, use_onnx=False, use_pdserving=False, use_space_char=True, use_tensorrt=False, vis_font_path='./doc/fonts/simfang.ttf', warmup=False)\n"]}],"source":["ocr = PaddleOCR(use_angle_cls=True, lang='ch')\n","table_engine = PPStructure(show_log=True)"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":319,"status":"ok","timestamp":1657314951282,"user":{"displayName":"Michael S","userId":"03226043462629562395"},"user_tz":-60},"id":"VEYr8b3v-9Lh","outputId":"f8506f57-81fc-4b19-df39-ec00abae39c7"},"outputs":[{"name":"stdout","output_type":"stream","text":["['ada.JPG', 'cgk.JPG', 'cgk_ae.JPG', 'ori.JPG', 'sha.JPG']\n"]}],"source":["input_path = './input/0858/'\n","#input_path = './binarize/binary/'\n","#input_path = './output/'\n","output_path = './output/0858/'\n","input_images_name = sorted(os.listdir(input_path))\n","print(input_images_name)"]},{"cell_type":"markdown","metadata":{},"source":["### Pre-processing & OCR functions"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[],"source":["def skew_angle_hough_transform(image):\n","    # convert to edges\n","    edges = canny(image, sigma=1)\n","    # Classic straight-line Hough transform.\n","    tested_angles = np.deg2rad(np.arange(75, 105))\n","    h, theta, d = hough_line(edges, theta=tested_angles)\n","    \n","    # find line peaks and angles\n","    accum, angles, dists = hough_line_peaks(h, theta, d)\n","    \n","    # round the angles to 2 decimal places and find the most common angle.\n","    most_common_angle = mode(np.around(angles, decimals=2))[0]\n","    \n","    # convert the angle to degree for rotation.\n","    skew_angle = np.rad2deg(most_common_angle - np.pi/2)\n","    print('Angle to correct:', skew_angle)\n","    return skew_angle\n","\n","def skew_correct(image):\n","    angle = skew_angle_hough_transform(image)[0]\n","    return imutils.rotate(image, angle)\n","\n","# Draw bounding boxes and text\n","def draw_image(path, bounds, color='red', width=2):\n","    myFont = ImageFont.truetype('data/font/msyh.ttc', 32)\n","    image = Image.open(path)\n","    image = image.convert('RGB')\n","    #image = image.rotate(270, expand=True) # uncomment this line if necessary\n","    draw = ImageDraw.Draw(image)\n","    for bound in bounds:\n","        p0, p1, p2, p3 = bound[0]\n","        draw.line([*p0, *p1, *p2, *p3, *p0], fill=color, width=width)\n","        draw.text(p3, bound[1][0], font=myFont, fill=(255, 0, 0))\n","    return image"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["def line_detection(path):\n","    raw = cv2.imread(path, 1)\n","    gray = cv2.cvtColor(raw, cv2.COLOR_BGR2GRAY)\n","    binary = cv2.adaptiveThreshold(~gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 35, -5)\n","    rows, cols = binary.shape\n","    \n","    scale = 50\n","    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (cols // scale, 1))\n","    eroded = cv2.erode(binary, kernel, iterations=1)\n","    dilated_col = cv2.dilate(eroded, kernel, iterations=1)\n","    \n","    #scale = 40\n","    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, rows // scale))\n","    eroded = cv2.erode(binary, kernel, iterations=1)\n","    dilated_row = cv2.dilate(eroded, kernel, iterations=1)\n","\n","    #result = cv2.add(dilated_col, dilated_row)\n","    result = cv2.bitwise_and(dilated_col, dilated_row)\n","    #result = cv2.add(result, binary)\n","    #result = skew_correct(result)\n","    return result\n","\n","def distance(p1, p2):\n","    return sqrt((p1[0]-p2[0])**2 + (p1[1]-p2[1])**2)\n","\n","def draw_line(path, lines):\n","    image = Image.open(path)\n","    draw = ImageDraw.Draw(image)\n","    for line in lines:\n","        draw.line([line[0], line[1]], fill='red', width=4)\n","    return image\n","\n","def ocr_sub(path, crop_lines):\n","    image = cv2.imread(path)\n","    table = []\n","    for line in crop_lines:\n","        sub = image[line[0][1]:line[1][1], line[0][0]:line[1][0]]\n","        result = ocr.ocr(sub)\n","        text = []\n","        for bound in result:\n","            text.append(bound[1][0])\n","        table.append(text)\n","        print(text)\n","    return table\n","\n","def write_xlsx(path, table):\n","    img_name = os.path.basename(path).split('.')[0]\n","    workbook = xlsxwriter.Workbook(output_path + img_name + '.xlsx')\n","    worksheet = workbook.add_worksheet()\n","    merge_format = workbook.add_format({'align': 'center'})\n","    row = 0\n","    column = 0\n","    for col in table:\n","        for item in col:\n","            worksheet.write(row, column, item)\n","            row += 1\n","        row = 0\n","        column += 1\n","    max_col_len = max([len(col) for col in table])\n","    for i in range(len(table)):\n","        if len(table[i]) == 1:\n","            worksheet.merge_range(0, i, max_col_len, i, table[i][0], merge_format)\n","    workbook.close()"]},{"cell_type":"markdown","metadata":{},"source":["### Pre-processing (optional)"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"data":{"text/plain":["True"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["image = cv2.imread(input_path + input_images_name[2])\n","kernel1 = np.array([[0, -1, 0],\n","                   [-1, 5,-1],\n","                   [0, -1, 0]])\n","kernel2 = np.array([[-1, -1, -1],\n","                   [-1, 10,-1],\n","                   [-1, -1, -1]])\n","image_sharp = cv2.filter2D(src=image, ddepth=-1, kernel=kernel1)\n","\n","cv2.imwrite(input_path+'sha.JPG', image_sharp)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"data":{"text/plain":["True"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["image = cv2.imread(input_path + input_images_name[8])\n","img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","binary = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 199, 20)\n","\n","kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (20, 20))\n","eroded = cv2.erode(binary, kernel, iterations=1)\n","dilated = cv2.dilate(eroded, kernel, iterations=1)\n","mask = cv2.bitwise_not(eroded)\n","mask = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)\n","\n","result = cv2.bitwise_and(image, mask)\n","result[mask==0] = 255\n","\n","cv2.imwrite(input_path+'b1.jpg', binary)"]},{"cell_type":"markdown","metadata":{},"source":["### Recognition Accuracy System"]},{"cell_type":"code","execution_count":89,"metadata":{},"outputs":[],"source":["def similarity(a, b):\n","    return SequenceMatcher(None, a, b).ratio()\n","\n","def read_lines(path):\n","    file = open(path, 'r')\n","    lines = file.read().splitlines()\n","    return lines\n","\n","def write_lines(lines, path):\n","    file = open(path, 'w')\n","    file.write('\\n'.join(lines))\n","\n","def cal_score(result, truth):\n","    matched_line = 0\n","    accuracy_sum = 0\n","    matched_char = 0\n","    truth_line_usage = [0]*len(truth)\n","    for res_line in result:\n","        for i in range(len(truth)):\n","            tru_line = truth[i]\n","            if similarity(res_line, tru_line) > 0.7 and truth_line_usage[i] == 0:\n","                truth_line_usage[i] = 1\n","                matched_line += 1\n","                accuracy_sum += similarity(res_line, tru_line)\n","                matched_char += similarity(res_line, tru_line)*len(tru_line)\n","    box_coverge = matched_line / len(truth)\n","    avg_box_accuracy = accuracy_sum / matched_line\n","    char_sum = sum([len(line) for line in truth])\n","    avg_char_accuracy = matched_char / char_sum\n","    \n","    return box_coverge, avg_box_accuracy, box_coverge*avg_box_accuracy, avg_char_accuracy"]},{"cell_type":"markdown","metadata":{},"source":["### Visualizing OCR results and recognition accuracy"]},{"cell_type":"code","execution_count":90,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["./input/0858/ada.JPG (0.9230769230769231, 0.9682030655600988, 0.8937259066708605, 0.8411707784034108)\n","./input/0858/cgk.JPG (0.8461538461538461, 0.9623945164698232, 0.8143338216283119, 0.8676324395850087)\n","./input/0858/cgk_ae.JPG (0.8615384615384616, 0.9545207415787943, 0.8223563312063459, 0.9169844523379639)\n","./input/0858/ori.JPG (0.8769230769230769, 0.971759656144054, 0.852158467695555, 0.9022214365011935)\n","./input/0858/sha.JPG (0.8615384615384616, 0.9491619269907278, 0.8177395063304732, 0.8718571899046756)\n"]}],"source":["ground_truth = read_lines(input_path + '0858.txt')\n","\n","# Save output images\n","for img_name in input_images_name:\n","    path = input_path + img_name\n","    #result = ocr.ocr(path, cls=True)\n","    #draw_image(path, result).save(output_path + img_name)\n","    #print(path)\n","    #result_text = [line[1][0] for line in result]\n","    result_text = read_lines(input_path+img_name[:-3]+'txt')\n","    #write_lines(result_text, input_path+img_name[:-3]+'txt')\n","    print(path, cal_score(result_text, ground_truth))"]},{"cell_type":"markdown","metadata":{},"source":["### Recognizing table directly using API"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":83797,"status":"ok","timestamp":1657315132188,"user":{"displayName":"Michael S","userId":"03226043462629562395"},"user_tz":-60},"id":"GRoRhT0m6Uf6","outputId":"ba5577e9-fc07-4772-de0b-ab5211290211"},"outputs":[{"name":"stdout","output_type":"stream","text":["./input/ucl/06DACF2E-1C2B-4BEE-8404-C6688D40F0DB.jpeg\n","./input/ucl/4D8D63EE-347E-4BA9-A87B-1762537D4A11.jpeg\n","./input/ucl/66358E1A-F799-466C-B6C2-9F91C2A134EE.jpeg\n","./input/ucl/694EE917-1594-4700-BEEB-E6AAFF5E0F70.jpeg\n","./input/ucl/B0523B2E-187A-4B30-A14F-D011195BA687.jpeg\n","./input/ucl/BD0B4AE8-9630-44F3-A02F-8264A84F7C05.jpeg\n","./input/ucl/E11B732C-86CB-4E86-BFDD-4100966B31AB.jpeg\n"]}],"source":["for img_name in input_images_name:\n","    path = input_path + img_name\n","    subfolder = os.path.basename(path).split('.')[0]\n","    img = cv2.imread(path)\n","    result = table_engine(img)\n","    save_structure_res(result, output_path, subfolder)\n","    print(path)"]},{"cell_type":"markdown","metadata":{},"source":["### Recognizing Type-3 (Fapiao) table"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for img_name in input_images_name[-1:]:\n","    path = input_path + img_name\n","    intersection = line_detection(path)\n","    ys, xs = np.where(intersection > 0)\n","    points = list(zip(xs, ys))\n","    anchors = [points[0]]\n","    for point in points[1:]:\n","        isvalid = True\n","        for anchor in anchors:\n","            if distance(anchor, point) < 50:\n","                isvalid = False\n","        if isvalid:\n","            anchors.append(point)\n","    #print(anchors)\n","    ys = np.array([point[1] for point in anchors]).reshape(-1, 1)\n","    clustering = DBSCAN(eps=50, min_samples=5).fit(ys)\n","    #print(clustering.labels_)\n","    labels = list(clustering.labels_)\n","    clusters = {}\n","    for i in range(len(labels)):\n","        if labels[i] >= 0:\n","            if labels[i] not in clusters:\n","                clusters[labels[i]] = []\n","            clusters[labels[i]].append(anchors[i])\n","    line = 0\n","    for cluster in clusters.values():\n","        cluster.sort(key=lambda tup: tup[0])\n","        print('Line ' + str(line) + ':', cluster)\n","        line += 1\n","    #print(clusters)\n","    crop_point = []\n","    for i in range(len(clusters)-1):\n","        comb1 = list(combinations(clusters[i], 2))\n","        comb2 = list(combinations(clusters[i+1], 2))\n","        found = (0, 0)\n","        for c1 in comb1:\n","            if found == c1[0]:\n","                continue\n","            for c2 in comb2:\n","                p1, p2, p3, p4 = c1[0], c1[1], c2[0], c2[1]\n","                if abs(p1[0]-p3[0])<25 and abs(p2[0]-p4[0])<25:\n","                    crop_point.append([p1, p4])\n","                    found = p1\n","                    break\n","    #print(crop_point)\n","    for pair in crop_point:\n","        print(pair)\n","    #print(len(crop_point))\n","    table = ocr_sub(path, crop_point)\n","    write_xlsx(path, table)\n","    draw_line(path, crop_point).save(output_path + img_name)\n","    print(path)"]},{"cell_type":"markdown","metadata":{},"source":["### Visualizing table cell detection"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for img_name in input_images_name[-1:]:\n","    path = input_path + img_name\n","    borders = line_detection(path)\n","    result = borders\n","    cv2.imwrite(output_path+img_name, result)\n","    print(path)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"name":"paddle_ocr.ipynb","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.8.10 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"vscode":{"interpreter":{"hash":"31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"}}},"nbformat":4,"nbformat_minor":0}
