{"cells":[{"cell_type":"markdown","metadata":{"id":"buqoideQiKJ4"},"source":["# Auto-encoders for Document Denoising"]},{"cell_type":"markdown","metadata":{"id":"wCKQ-4cWiKJ6"},"source":["## About Autoencoders\n","An autoencoder is a type of artificial neural network used to learn efficient data codings in an unsupervised manner. The aim of an autoencoder is to learn a representation (encoding) for a set of data, typically for dimensionality reduction, by training the network to ignore signal “noise”. Along with the reduction side, a reconstructing side is learnt, where the autoencoder tries to generate from the reduced encoding a representation as close as possible to its original input, hence its name."]},{"cell_type":"markdown","metadata":{"id":"9j5Dk3KLiKJ6"},"source":["![](https://osclasspoint.com/kaggle/autoencoder.png)"]},{"cell_type":"markdown","metadata":{"id":"txBpPaH5iKJ7"},"source":["## Import libraries and data"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3772,"status":"ok","timestamp":1656150230499,"user":{"displayName":"Michael S","userId":"03226043462629562395"},"user_tz":-60},"id":"6vfAM4oQiKJ7"},"outputs":[],"source":["import numpy as np\n","import matplotlib as mpl\n","import os\n","import cv2\n","\n","import tensorflow as tf\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Dropout, BatchNormalization, Input\n","\n","%matplotlib inline"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22248,"status":"ok","timestamp":1656150252730,"user":{"displayName":"Michael S","userId":"03226043462629562395"},"user_tz":-60},"id":"CL6oepWtiirk","outputId":"8a9c8431-1a0f-4ed1-cf69-aafb3d12bfd5"},"outputs":[],"source":["# special need for Google Colab\n","from google.colab import drive\n","drive.mount('/content/drive')\n","os.chdir(\"/content/drive/MyDrive/ColabNotebooks/DocDenoise\")\n","!ls"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":499,"status":"ok","timestamp":1656150253222,"user":{"displayName":"Michael S","userId":"03226043462629562395"},"user_tz":-60},"id":"7DQz485ajYMu","outputId":"131ce9cc-a985-47e5-c1e6-61dfd9a064af"},"outputs":[],"source":["# check GPU details\n","!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","executionInfo":{"elapsed":246,"status":"ok","timestamp":1656150626445,"user":{"displayName":"Michael S","userId":"03226043462629562395"},"user_tz":-60},"id":"HDz7lYu7iKJ8"},"outputs":[],"source":["# the whole data path\n","path = 'data/'\n","# the directory storing images to be processed\n","to_process_path = 'to_process/'\n","# the directory storing processed images\n","processed_path = 'processed/'\n","# list storing image filenames\n","to_process_img = sorted(os.listdir(path + to_process_path))"]},{"cell_type":"markdown","metadata":{"id":"wHeUOFDHiKJ9"},"source":["## Data preparation\n","Next step is to define function to process images and then store this images in list. As there is not as many data, we do not need to work in batches."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":238,"status":"ok","timestamp":1656150628495,"user":{"displayName":"Michael S","userId":"03226043462629562395"},"user_tz":-60},"id":"X9nRriQqiKJ9"},"outputs":[],"source":["IMG_WIDTH = 3024\n","IMG_HEIGHT = 4032\n","\n","# prepare function\n","def process_image(path):\n","    img = cv2.imread(path)\n","    img = np.asarray(img, dtype=\"float32\")\n","    img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))\n","    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","    img = img/255.0\n","    img = np.reshape(img, (IMG_HEIGHT, IMG_WIDTH, 1))\n","    \n","    return img"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":10881,"status":"ok","timestamp":1656150649495,"user":{"displayName":"Michael S","userId":"03226043462629562395"},"user_tz":-60},"id":"l4w3qrPziKJ9"},"outputs":[],"source":["# preprocess images\n","test_chinese = []\n","\n","for f in to_process_img:\n","    test_chinese.append(process_image(path + to_process_path + f))\n","\n","test_chinese = np.asarray(test_chinese)"]},{"cell_type":"markdown","metadata":{"id":"qFiab7uAiKJ_"},"source":["## Modeling"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4034,"status":"ok","timestamp":1656150519591,"user":{"displayName":"Michael S","userId":"03226043462629562395"},"user_tz":-60},"id":"ygbtMgK_iKKA","outputId":"49247359-14dd-46dc-abad-c681c9350782"},"outputs":[],"source":["def model():\n","    input_layer = Input(shape=(IMG_HEIGHT, IMG_WIDTH, 1))\n","    \n","    # encoding\n","    x = Conv2D(64, (3, 3), activation='relu', padding='same')(input_layer)\n","    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n","    x = BatchNormalization()(x)\n","\n","    x = MaxPooling2D((2, 2), padding='same')(x)\n","    \n","    x = Dropout(0.5)(x)\n","\n","    # decoding\n","    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n","    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n","    x = BatchNormalization()(x)\n","\n","    x = UpSampling2D((2, 2))(x)\n","\n","    output_layer = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n","    model = Model(inputs=[input_layer], outputs=[output_layer])\n","    opt = tf.keras.optimizers.Adam()\n","    model.compile(optimizer=opt, loss='mean_squared_error', metrics=['mae'])\n","\n","    return model\n","\n","\n","model = model()\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"1NlQq3bbiKKA"},"source":["### Load model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":622,"status":"ok","timestamp":1656150583655,"user":{"displayName":"Michael S","userId":"03226043462629562395"},"user_tz":-60},"id":"TZMue83qiKKB","outputId":"0315e61a-1c58-4ba3-edc1-c745639ef8fc"},"outputs":[],"source":["# Restore the weights\n","model.load_weights('./checkpoints/autoencoders/checkpoint_kaggle_80eps')"]},{"cell_type":"markdown","metadata":{"id":"iVR2dOLhiKKC"},"source":["## Denoising and Save images"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":11885,"status":"error","timestamp":1656150935772,"user":{"displayName":"Michael S","userId":"03226043462629562395"},"user_tz":-60},"id":"eXpf1njC9kpM","outputId":"800dad7b-591e-4007-dce4-bd65ba910e6f"},"outputs":[],"source":["Y_test_chinese = model.predict(test_chinese, verbose=1, batch_size=1)\n","i = 0\n","for image in Y_test_chinese:\n","  im_path = path + processed_path + to_process_img[i]\n","  mpl.image.imsave(im_path, image[:,:,0], cmap='gray')\n","  i += 1"]},{"cell_type":"markdown","metadata":{"id":"jli9wIuumGFw"},"source":["## Next steps\n","- Training the model on a larger dataset\n","- Tuning parameters to achieve greater performance\n","- Fine-tuning the models on a different dataset to implement more functions (e.g., watermark removal and motion deblur)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"chineseInvoice_ae.ipynb","provenance":[{"file_id":"19URBkrJIBJCQLbdhtXV7DosvUR3AL_fZ","timestamp":1656006022589}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"nbformat":4,"nbformat_minor":0}
